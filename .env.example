# MCP server transport configuration
TRANSPORT=sse
HOST=0.0.0.0
PORT=8051

# database configuration
POSTGRES_USER=postgres
POSTGRES_PASSWORD=changeme
POSTGRES_DB=crawlrag
POSTGRES_URL=postgresql://postgres:changeme@rag-db:5432/crawlrag
DATABASE_NAME=crawlrag

# ollama configuration
OLLAMA_API_URL=http://host.docker.internal:11434/api/embeddings
OLLAMA_EMBED_MODEL=bge-m3-FP16
OLLAMA_EMBEDDING_DIM=1024

# contextual embeddings (optional, but greatly improves RAG accuracy)
# The LLM you want to use for contextual embeddings (contextual retrieval)
# Leave blank if you do not want to use contextual embeddings
# Generally use a cheap and fast LLM like gpt-4.1-nano or equivalent
LLM_ENABLED=false
# Base URL for OpenAI compatible endpoint
LLM_BASE_URL=https://openrouter.ai/api/v1
# API key for the chosen provider
LLM_API_KEY=
# Model name to use (e.g., "gpt-4.1-nano" for OpenAI, "<provider>/<model>" for OpenRouter)
LLM_MODEL_NAME=openai/gpt-4.1-nano
