import logging
import sys
import os

# Ensure src is in path for imports
sys.path.insert(0, os.path.abspath(os.path.join(os.path.dirname(__file__), '.')))

try:
    from src.utils import (
        get_session,
        CrawledPage,
        create_embedding,
        calculate_cosine_similarity,
        settings # For OLLAMA_EMBED_MODEL and OLLAMA_EMBEDDING_DIM
    )
    from sqlmodel import select
    from dotenv import load_dotenv
except ImportError as e:
    print(f"Error importing from src.utils: {e}")
    print("Please ensure this script is run from the project root or PYTHONPATH is set correctly.")
    exit(1)

logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

def check_self_similarity(text1: str, text2: str):
    logger.info(f"Testing self-similarity between: '{text1}' AND '{text2}'")
    logger.info(f"Using embedding model: {settings.OLLAMA_EMBED_MODEL} with dimension: {settings.OLLAMA_EMBEDDING_DIM}")

    try:
        logger.info(f"Creating embedding for text 1: '{text1}'...")
        embedding1 = create_embedding(text1)
        logger.info(f"Embedding 1 created (first 10 values): {embedding1[:10]}")

        logger.info(f"Creating embedding for text 2: '{text2}'...")
        embedding2 = create_embedding(text2)
        logger.info(f"Embedding 2 created (first 10 values): {embedding2[:10]}")

        similarity = calculate_cosine_similarity(embedding1, embedding2)
        logger.info(f"Calculated Python similarity between text 1 and text 2: {similarity:.4f}")

        if text1 == text2 and similarity < 0.99: # Expect very high similarity for identical texts
            logger.error(f"CRITICAL SANITY CHECK FAILED: Similarity for identical texts is unexpectedly low: {similarity:.4f}")
        elif text1 != text2 and similarity < 0.5 and "different" in text1 and "different" in text2: # Basic check for different texts
             logger.info(f"Sanity check for different texts: score is {similarity:.4f}, which is expected to be lower.")
        elif similarity > 0.99:
             logger.info(f"Sanity check passed: Similarity is high as expected: {similarity:.4f}")


    except Exception as e:
        logger.error(f"An error occurred during self-similarity testing: {e}", exc_info=True)


# def test_specific_chunk_similarity(chunk_id: int, query_text: str):
#     logger.info(f"Testing similarity for chunk ID: {chunk_id} against query: '{query_text}'")
#     logger.info(f"Using embedding model: {settings.OLLAMA_EMBED_MODEL} with dimension: {settings.OLLAMA_EMBEDDING_DIM}")

#     with next(get_session()) as session:
#         # Fetch the specific chunk
#         statement = select(CrawledPage).where(CrawledPage.id == chunk_id)
#         chunk = session.exec(statement).one_or_none()

#         if not chunk:
#             logger.error(f"Chunk with ID {chunk_id} not found.")
#             return

#         if not chunk.content or not chunk.content.strip():
#             logger.error(f"Chunk ID {chunk_id} has empty content. Cannot test similarity.")
#             return

#         logger.info(f"Full stored content of chunk ID {chunk_id} (first 300 chars): {chunk.content[:300]}...")

#         # Attempt to isolate original chunk content if contextual embedding was applied
#         original_chunk_content = chunk.content
#         separator_used = None

#         # Try splitting by the intended separator first
#         if "\\n---\\n" in chunk.content: # As generated by src.utils.generate_contextual_embedding
#             parts = chunk.content.split("\\n---\\n", 1)
#             if len(parts) > 1:
#                 original_chunk_content = parts[1]
#                 separator_used = "\\n---\\n"
#         # If not found, try splitting by "---" which might be what's actually in the DB content
#         # This handles cases where the leading newline before "---" might be missing in the stored data.
#         elif "---" in chunk.content:
#             parts = chunk.content.split("---", 1)
#             if len(parts) > 1:
#                 # Remove any leading whitespace (including newlines) from the original chunk part
#                 original_chunk_content = parts[1].lstrip()
#                 separator_used = "---"
        
#         if separator_used:
#             logger.info(f"Isolated original chunk content using separator '{separator_used}' (first 300 chars): {original_chunk_content[:300]}...")
#         else:
#             logger.info("No '---' or '\\n---\\n' separator found. Assuming content is original or context is not separable as expected. Using full content.")

#         try:
#             # Create embedding for the (potentially isolated original) chunk's content
#             logger.info(f"Creating embedding for content (separator used: '{separator_used if separator_used else 'None'}') of chunk ID {chunk_id}...")
#             document_embedding = create_embedding(original_chunk_content)
#             logger.info(f"Document embedding created (first 10 values): {document_embedding[:10]}")

#             # Create embedding for the query
#             logger.info(f"Creating embedding for query: '{query_text}'...")
#             query_embedding = create_embedding(query_text)
#             logger.info(f"Query embedding created (first 10 values): {query_embedding[:10]}")

#             # Calculate similarity
#             similarity = calculate_cosine_similarity(query_embedding, document_embedding)
#             logger.info(f"Calculated Python similarity between query and chunk ID {chunk_id}: {similarity:.4f}")

#         except Exception as e:
#             logger.error(f"An error occurred during similarity testing: {e}", exc_info=True)

if __name__ == "__main__":
    if load_dotenv():
        logger.info(".env file loaded successfully for debug script.")
    else:
        logger.warning(".env file not found for debug script. Using existing environment variables or defaults.")

    # target_chunk_id = 166
    # # test_query = "endpoint variables"
    # # Let's use a query string that is an exact part of the target document's content
    # test_query = "Endpoints environment variables"
    # logger.info(f"MODIFIED SCRIPT: Using exact phrase from document as query: '{test_query}'")
    # test_specific_chunk_similarity(target_chunk_id, test_query)

    # logger.info("Performing self-similarity sanity check...")
    # sentence1 = "This is a test sentence."
    # sentence2 = "This is a test sentence."
    # sentence3 = "This is a completely different sentence."
    # check_self_similarity(sentence1, sentence2)
    # check_self_similarity(sentence1, sentence3)

    logger.info("Performing specific sentence from doc vs. query test...")
    specific_sentence_from_doc = "This page lists environment variables for customizing endpoints in n8n."
    query_text = "endpoint variables"
    logger.info(f"Testing: '{specific_sentence_from_doc}' vs '{query_text}'")
    check_self_similarity(specific_sentence_from_doc, query_text) # Reusing check_self_similarity to compare two arbitrary strings