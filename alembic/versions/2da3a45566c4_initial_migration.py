"""Initial migration

Revision ID: 2da3a45566c4
Revises: 
Create Date: 2025-05-08 02:17:29.031256

"""
from typing import Sequence, Union

from alembic import op
import sqlalchemy as sa


# revision identifiers, used by Alembic.
revision: str = '2da3a45566c4'
down_revision: Union[str, None] = None
branch_labels: Union[str, Sequence[str], None] = None
depends_on: Union[str, Sequence[str], None] = None


def upgrade() -> None:
    """Upgrade schema."""
    # ### commands auto generated by Alembic - please adjust! ###
    op.drop_index('crawledpage_embedding_idx', table_name='crawledpage', postgresql_using='ivfflat')
    op.drop_index('idx_crawledpage_metadata', table_name='crawledpage', postgresql_using='gin')
    op.drop_index('idx_crawledpage_source', table_name='crawledpage')
    # ### end Alembic commands ###

    # Manually added commands to fix datatype mismatch and update function/indexes
    # Reason: Autogenerate did not detect changes to column type or function definition.

    # Import settings to get embedding dimension
    from src.utils import settings

    # Alter 'id' column to BIGINT. This assumes the sequence is handled correctly by PG/Alembic.
    # If this fails, a more complex migration involving temporary table might be needed.
    op.alter_column(
        'crawledpage',
        'id',
        type_=sa.BigInteger(),
        autoincrement=True, # Keep autoincrement property
        existing_type=sa.Integer(), # Specify existing type for clarity/safety
        postgresql_using='id::BIGINT' # Optional: hint for casting existing data
    )

    # Recreate the match_crawledpage function with the correct definition
    # Use op.execute for raw SQL
    function_sql = f"""
CREATE OR REPLACE FUNCTION match_crawledpage (
  query_embedding vector({settings.OLLAMA_EMBEDDING_DIM}),
  match_count int default 10,
  filter jsonb DEFAULT '{{}}'::jsonb
) RETURNS table (
  id bigint,
  url varchar,
  chunk_number integer,
  content text,
  metadata jsonb,
  similarity float
)
language plpgsql
as $$
#variable_conflict use_column
begin
  SET LOCAL ivfflat.probes = 10; -- Or a higher value if needed, e.g., 15 or 20
  return query
  select
    id::BIGINT,
    url,
    chunk_number,
    content,
    metadata,
    1 - (crawledpage.embedding <=> query_embedding) as similarity
  from crawledpage
  where metadata @> filter
  order by crawledpage.embedding <=> query_embedding
  limit match_count;
  -- Debug logging can be enabled here with:
  -- RAISE NOTICE 'Executed match_crawledpage with filter %', filter;
end;
$$;
    """
    op.execute(function_sql)

    # Recreate the dropped indexes
    op.create_index('crawledpage_embedding_idx', 'crawledpage', ['embedding'], unique=False, postgresql_using='ivfflat', postgresql_ops={'embedding': 'vector_cosine_ops'})
    op.create_index('idx_crawledpage_metadata', 'crawledpage', ['metadata'], unique=False, postgresql_using='gin')
    op.create_index('idx_crawledpage_source', 'crawledpage', [sa.text("(metadata->>'source')")], unique=False)


def downgrade() -> None:
    """Downgrade schema."""
    # ### commands auto generated by Alembic - please adjust! ###
    op.create_index('idx_crawledpage_source', 'crawledpage', [sa.literal_column("(metadata ->> 'source'::text)")], unique=False)
    op.create_index('idx_crawledpage_metadata', 'crawledpage', ['metadata'], unique=False, postgresql_using='gin')
    op.create_index('crawledpage_embedding_idx', 'crawledpage', ['embedding'], unique=False, postgresql_using='ivfflat')
    # ### end Alembic commands ###
